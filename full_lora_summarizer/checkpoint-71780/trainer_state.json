{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 71780,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.3450377285480499,
      "learning_rate": 0.0001990749512398997,
      "loss": 1.8642,
      "step": 500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.34764501452445984,
      "learning_rate": 0.00019814618742453795,
      "loss": 1.1861,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3683773875236511,
      "learning_rate": 0.00019721742360917618,
      "loss": 1.1978,
      "step": 1500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3501841425895691,
      "learning_rate": 0.00019628865979381442,
      "loss": 1.201,
      "step": 2000
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3124912977218628,
      "learning_rate": 0.00019535989597845268,
      "loss": 1.1944,
      "step": 2500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3585123121738434,
      "learning_rate": 0.00019443113216309095,
      "loss": 1.178,
      "step": 3000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2870616614818573,
      "learning_rate": 0.00019350236834772918,
      "loss": 1.1766,
      "step": 3500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.32035091519355774,
      "learning_rate": 0.00019257360453236744,
      "loss": 1.1921,
      "step": 4000
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3001229465007782,
      "learning_rate": 0.00019164484071700568,
      "loss": 1.1861,
      "step": 4500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3355891704559326,
      "learning_rate": 0.00019071607690164392,
      "loss": 1.1736,
      "step": 5000
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.27807384729385376,
      "learning_rate": 0.00018978917061391289,
      "loss": 1.1666,
      "step": 5500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2920401692390442,
      "learning_rate": 0.00018886226432618186,
      "loss": 1.1947,
      "step": 6000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.30107954144477844,
      "learning_rate": 0.0001879335005108201,
      "loss": 1.1712,
      "step": 6500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.30822938680648804,
      "learning_rate": 0.00018700473669545835,
      "loss": 1.1725,
      "step": 7000
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.27871984243392944,
      "learning_rate": 0.0001860759728800966,
      "loss": 1.1908,
      "step": 7500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.31903931498527527,
      "learning_rate": 0.00018514720906473485,
      "loss": 1.1731,
      "step": 8000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.29311826825141907,
      "learning_rate": 0.0001842184452493731,
      "loss": 1.1735,
      "step": 8500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4109500050544739,
      "learning_rate": 0.00018328968143401132,
      "loss": 1.1743,
      "step": 9000
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2619941532611847,
      "learning_rate": 0.00018236091761864959,
      "loss": 1.1777,
      "step": 9500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2513294816017151,
      "learning_rate": 0.00018143215380328785,
      "loss": 1.1758,
      "step": 10000
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2908726930618286,
      "learning_rate": 0.00018050338998792608,
      "loss": 1.1836,
      "step": 10500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3014145493507385,
      "learning_rate": 0.00017957462617256432,
      "loss": 1.1671,
      "step": 11000
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.2681078612804413,
      "learning_rate": 0.0001786477198848333,
      "loss": 1.1746,
      "step": 11500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3334319591522217,
      "learning_rate": 0.00017771895606947152,
      "loss": 1.1749,
      "step": 12000
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.36518585681915283,
      "learning_rate": 0.0001767901922541098,
      "loss": 1.1727,
      "step": 12500
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.35169506072998047,
      "learning_rate": 0.00017586142843874805,
      "loss": 1.1857,
      "step": 13000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.2977708876132965,
      "learning_rate": 0.00017493266462338629,
      "loss": 1.1625,
      "step": 13500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.26458442211151123,
      "learning_rate": 0.00017400390080802452,
      "loss": 1.1903,
      "step": 14000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.30346596240997314,
      "learning_rate": 0.00017307513699266278,
      "loss": 1.1571,
      "step": 14500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.28524842858314514,
      "learning_rate": 0.00017214637317730102,
      "loss": 1.1714,
      "step": 15000
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.2825820744037628,
      "learning_rate": 0.00017121946688957,
      "loss": 1.1798,
      "step": 15500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.2857975661754608,
      "learning_rate": 0.00017029070307420825,
      "loss": 1.1654,
      "step": 16000
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3397250473499298,
      "learning_rate": 0.0001693619392588465,
      "loss": 1.1435,
      "step": 16500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.316167950630188,
      "learning_rate": 0.00016843317544348472,
      "loss": 1.1733,
      "step": 17000
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.33190304040908813,
      "learning_rate": 0.0001675062691557537,
      "loss": 1.152,
      "step": 17500
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.25945720076560974,
      "learning_rate": 0.00016657750534039193,
      "loss": 1.1581,
      "step": 18000
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3242326080799103,
      "learning_rate": 0.00016565059905266093,
      "loss": 1.1689,
      "step": 18500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.2978721857070923,
      "learning_rate": 0.00016472183523729916,
      "loss": 1.1488,
      "step": 19000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3430033326148987,
      "learning_rate": 0.0001637930714219374,
      "loss": 1.1705,
      "step": 19500
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.28607654571533203,
      "learning_rate": 0.00016286430760657566,
      "loss": 1.1562,
      "step": 20000
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.31207534670829773,
      "learning_rate": 0.0001619355437912139,
      "loss": 1.1549,
      "step": 20500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3084670305252075,
      "learning_rate": 0.00016100677997585213,
      "loss": 1.1722,
      "step": 21000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2825249433517456,
      "learning_rate": 0.00016007987368812113,
      "loss": 1.1594,
      "step": 21500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.28111013770103455,
      "learning_rate": 0.00015915110987275936,
      "loss": 1.16,
      "step": 22000
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3423774242401123,
      "learning_rate": 0.0001582223460573976,
      "loss": 1.15,
      "step": 22500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2619463801383972,
      "learning_rate": 0.00015729358224203586,
      "loss": 1.152,
      "step": 23000
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3091576397418976,
      "learning_rate": 0.0001563648184266741,
      "loss": 1.1716,
      "step": 23500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.28861111402511597,
      "learning_rate": 0.00015543605461131233,
      "loss": 1.1647,
      "step": 24000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.26915061473846436,
      "learning_rate": 0.0001545072907959506,
      "loss": 1.1557,
      "step": 24500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3115215003490448,
      "learning_rate": 0.00015358038450821957,
      "loss": 1.1548,
      "step": 25000
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.30721601843833923,
      "learning_rate": 0.0001526516206928578,
      "loss": 1.16,
      "step": 25500
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3231692314147949,
      "learning_rate": 0.00015172285687749606,
      "loss": 1.1469,
      "step": 26000
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.2847815155982971,
      "learning_rate": 0.0001507940930621343,
      "loss": 1.1851,
      "step": 26500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.31246745586395264,
      "learning_rate": 0.00014986532924677253,
      "loss": 1.1514,
      "step": 27000
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.2858879268169403,
      "learning_rate": 0.0001489365654314108,
      "loss": 1.164,
      "step": 27500
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2564058005809784,
      "learning_rate": 0.00014800780161604903,
      "loss": 1.1571,
      "step": 28000
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.33218711614608765,
      "learning_rate": 0.000147080895328318,
      "loss": 1.167,
      "step": 28500
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.286456435918808,
      "learning_rate": 0.000146153989040587,
      "loss": 1.1563,
      "step": 29000
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.33347150683403015,
      "learning_rate": 0.00014522522522522524,
      "loss": 1.1731,
      "step": 29500
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.273801326751709,
      "learning_rate": 0.00014429646140986347,
      "loss": 1.1652,
      "step": 30000
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3594479560852051,
      "learning_rate": 0.00014336769759450173,
      "loss": 1.1687,
      "step": 30500
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3516223728656769,
      "learning_rate": 0.00014243893377913997,
      "loss": 1.1713,
      "step": 31000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2991117537021637,
      "learning_rate": 0.0001415101699637782,
      "loss": 1.1596,
      "step": 31500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.2956375777721405,
      "learning_rate": 0.00014058140614841647,
      "loss": 1.1623,
      "step": 32000
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.30753782391548157,
      "learning_rate": 0.0001396526423330547,
      "loss": 1.1635,
      "step": 32500
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3137337565422058,
      "learning_rate": 0.00013872387851769294,
      "loss": 1.1698,
      "step": 33000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3138163387775421,
      "learning_rate": 0.0001377951147023312,
      "loss": 1.1549,
      "step": 33500
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.2975803017616272,
      "learning_rate": 0.00013686820841460017,
      "loss": 1.1648,
      "step": 34000
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.30275940895080566,
      "learning_rate": 0.0001359394445992384,
      "loss": 1.1718,
      "step": 34500
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.2864631712436676,
      "learning_rate": 0.00013501068078387667,
      "loss": 1.1577,
      "step": 35000
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2997587323188782,
      "learning_rate": 0.0001340819169685149,
      "loss": 1.1646,
      "step": 35500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.154471516609192,
      "eval_runtime": 66.8164,
      "eval_samples_per_second": 200.071,
      "eval_steps_per_second": 25.009,
      "step": 35890
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.27922436594963074,
      "learning_rate": 0.00013315501068078388,
      "loss": 1.16,
      "step": 36000
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2673499584197998,
      "learning_rate": 0.00013222624686542214,
      "loss": 1.1527,
      "step": 36500
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.31780701875686646,
      "learning_rate": 0.00013129748305006037,
      "loss": 1.165,
      "step": 37000
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.2743293046951294,
      "learning_rate": 0.0001303687192346986,
      "loss": 1.1612,
      "step": 37500
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.3103017807006836,
      "learning_rate": 0.0001294418129469676,
      "loss": 1.1492,
      "step": 38000
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.31575414538383484,
      "learning_rate": 0.00012851304913160584,
      "loss": 1.1596,
      "step": 38500
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.29905617237091064,
      "learning_rate": 0.00012758428531624408,
      "loss": 1.1668,
      "step": 39000
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.31431466341018677,
      "learning_rate": 0.00012665552150088234,
      "loss": 1.1485,
      "step": 39500
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.34300199151039124,
      "learning_rate": 0.00012572675768552058,
      "loss": 1.1681,
      "step": 40000
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.3621000647544861,
      "learning_rate": 0.0001247979938701588,
      "loss": 1.1511,
      "step": 40500
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.27860385179519653,
      "learning_rate": 0.00012386923005479707,
      "loss": 1.1643,
      "step": 41000
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.256878525018692,
      "learning_rate": 0.0001229404662394353,
      "loss": 1.1538,
      "step": 41500
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.2733500897884369,
      "learning_rate": 0.00012201355995170429,
      "loss": 1.1601,
      "step": 42000
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.3330339789390564,
      "learning_rate": 0.00012108479613634254,
      "loss": 1.154,
      "step": 42500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.33120524883270264,
      "learning_rate": 0.00012015603232098078,
      "loss": 1.1739,
      "step": 43000
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.33479630947113037,
      "learning_rate": 0.00011922726850561903,
      "loss": 1.1596,
      "step": 43500
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2980976104736328,
      "learning_rate": 0.00011829850469025728,
      "loss": 1.1793,
      "step": 44000
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2867085635662079,
      "learning_rate": 0.00011736974087489551,
      "loss": 1.1669,
      "step": 44500
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.30577653646469116,
      "learning_rate": 0.00011644097705953376,
      "loss": 1.1664,
      "step": 45000
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.3085036873817444,
      "learning_rate": 0.00011551221324417201,
      "loss": 1.1629,
      "step": 45500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.29713186621665955,
      "learning_rate": 0.00011458530695644098,
      "loss": 1.1447,
      "step": 46000
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.32120010256767273,
      "learning_rate": 0.00011365654314107923,
      "loss": 1.1516,
      "step": 46500
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.28039196133613586,
      "learning_rate": 0.00011272777932571748,
      "loss": 1.1658,
      "step": 47000
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.2849559783935547,
      "learning_rate": 0.00011179901551035571,
      "loss": 1.1411,
      "step": 47500
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.37301352620124817,
      "learning_rate": 0.0001108721092226247,
      "loss": 1.1663,
      "step": 48000
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.3063981235027313,
      "learning_rate": 0.00010994334540726295,
      "loss": 1.147,
      "step": 48500
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.30691176652908325,
      "learning_rate": 0.00010901458159190118,
      "loss": 1.1661,
      "step": 49000
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.2649722397327423,
      "learning_rate": 0.00010808581777653943,
      "loss": 1.1432,
      "step": 49500
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.31021204590797424,
      "learning_rate": 0.00010715705396117768,
      "loss": 1.1652,
      "step": 50000
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.34651508927345276,
      "learning_rate": 0.00010622829014581593,
      "loss": 1.1666,
      "step": 50500
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.29828688502311707,
      "learning_rate": 0.00010529952633045416,
      "loss": 1.1637,
      "step": 51000
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.3078192174434662,
      "learning_rate": 0.00010437076251509241,
      "loss": 1.1855,
      "step": 51500
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.3145574927330017,
      "learning_rate": 0.00010344199869973066,
      "loss": 1.1662,
      "step": 52000
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.27572983503341675,
      "learning_rate": 0.00010251509241199963,
      "loss": 1.1605,
      "step": 52500
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2902051508426666,
      "learning_rate": 0.00010158632859663788,
      "loss": 1.1544,
      "step": 53000
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.2656576335430145,
      "learning_rate": 0.00010065756478127613,
      "loss": 1.1548,
      "step": 53500
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.34100478887557983,
      "learning_rate": 9.972880096591437e-05,
      "loss": 1.1587,
      "step": 54000
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.30414387583732605,
      "learning_rate": 9.880003715055262e-05,
      "loss": 1.1599,
      "step": 54500
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.32570070028305054,
      "learning_rate": 9.787127333519086e-05,
      "loss": 1.1658,
      "step": 55000
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.3142200708389282,
      "learning_rate": 9.694250951982911e-05,
      "loss": 1.1414,
      "step": 55500
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.30952581763267517,
      "learning_rate": 9.601374570446736e-05,
      "loss": 1.1528,
      "step": 56000
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.3323597311973572,
      "learning_rate": 9.508683941673633e-05,
      "loss": 1.1708,
      "step": 56500
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.3156532347202301,
      "learning_rate": 9.415807560137457e-05,
      "loss": 1.1472,
      "step": 57000
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.329536497592926,
      "learning_rate": 9.322931178601282e-05,
      "loss": 1.1645,
      "step": 57500
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.3492265045642853,
      "learning_rate": 9.230054797065107e-05,
      "loss": 1.16,
      "step": 58000
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.28792425990104675,
      "learning_rate": 9.137549921055076e-05,
      "loss": 1.1518,
      "step": 58500
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.31680813431739807,
      "learning_rate": 9.0446735395189e-05,
      "loss": 1.1605,
      "step": 59000
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2534569203853607,
      "learning_rate": 8.951797157982726e-05,
      "loss": 1.1542,
      "step": 59500
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.341339647769928,
      "learning_rate": 8.85892077644655e-05,
      "loss": 1.1688,
      "step": 60000
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.2409754991531372,
      "learning_rate": 8.766044394910374e-05,
      "loss": 1.1678,
      "step": 60500
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.3033386468887329,
      "learning_rate": 8.673168013374199e-05,
      "loss": 1.1542,
      "step": 61000
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.29392698407173157,
      "learning_rate": 8.580291631838024e-05,
      "loss": 1.15,
      "step": 61500
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.28256407380104065,
      "learning_rate": 8.487415250301849e-05,
      "loss": 1.1573,
      "step": 62000
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.2754587233066559,
      "learning_rate": 8.394724621528746e-05,
      "loss": 1.1732,
      "step": 62500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.28353381156921387,
      "learning_rate": 8.302033992755643e-05,
      "loss": 1.1633,
      "step": 63000
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.30000683665275574,
      "learning_rate": 8.209157611219466e-05,
      "loss": 1.1622,
      "step": 63500
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.31057626008987427,
      "learning_rate": 8.116281229683293e-05,
      "loss": 1.1689,
      "step": 64000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.30336257815361023,
      "learning_rate": 8.02359060091019e-05,
      "loss": 1.1699,
      "step": 64500
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.2914707362651825,
      "learning_rate": 7.930714219374013e-05,
      "loss": 1.1424,
      "step": 65000
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.25281965732574463,
      "learning_rate": 7.837837837837838e-05,
      "loss": 1.1726,
      "step": 65500
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.27423256635665894,
      "learning_rate": 7.744961456301663e-05,
      "loss": 1.1685,
      "step": 66000
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.31427210569381714,
      "learning_rate": 7.652085074765487e-05,
      "loss": 1.1582,
      "step": 66500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.3473736047744751,
      "learning_rate": 7.559208693229313e-05,
      "loss": 1.1616,
      "step": 67000
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.3089316785335541,
      "learning_rate": 7.466332311693138e-05,
      "loss": 1.1486,
      "step": 67500
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.37206095457077026,
      "learning_rate": 7.373455930156961e-05,
      "loss": 1.1469,
      "step": 68000
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.31066790223121643,
      "learning_rate": 7.280579548620786e-05,
      "loss": 1.1596,
      "step": 68500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.3369779586791992,
      "learning_rate": 7.187703167084611e-05,
      "loss": 1.1479,
      "step": 69000
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.35136187076568604,
      "learning_rate": 7.094826785548435e-05,
      "loss": 1.1476,
      "step": 69500
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.3086129426956177,
      "learning_rate": 7.00195040401226e-05,
      "loss": 1.1715,
      "step": 70000
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.324016809463501,
      "learning_rate": 6.909259775239158e-05,
      "loss": 1.145,
      "step": 70500
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.3090330958366394,
      "learning_rate": 6.816383393702981e-05,
      "loss": 1.1582,
      "step": 71000
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.28177815675735474,
      "learning_rate": 6.723692764929878e-05,
      "loss": 1.167,
      "step": 71500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.1495018005371094,
      "eval_runtime": 66.8193,
      "eval_samples_per_second": 200.062,
      "eval_steps_per_second": 25.008,
      "step": 71780
    }
  ],
  "logging_steps": 500,
  "max_steps": 107670,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 7.823701262834074e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
