{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 107670,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 0.3450377285480499,
      "learning_rate": 0.0001990749512398997,
      "loss": 1.8642,
      "step": 500
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.34764501452445984,
      "learning_rate": 0.00019814618742453795,
      "loss": 1.1861,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3683773875236511,
      "learning_rate": 0.00019721742360917618,
      "loss": 1.1978,
      "step": 1500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3501841425895691,
      "learning_rate": 0.00019628865979381442,
      "loss": 1.201,
      "step": 2000
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3124912977218628,
      "learning_rate": 0.00019535989597845268,
      "loss": 1.1944,
      "step": 2500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.3585123121738434,
      "learning_rate": 0.00019443113216309095,
      "loss": 1.178,
      "step": 3000
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2870616614818573,
      "learning_rate": 0.00019350236834772918,
      "loss": 1.1766,
      "step": 3500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.32035091519355774,
      "learning_rate": 0.00019257360453236744,
      "loss": 1.1921,
      "step": 4000
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3001229465007782,
      "learning_rate": 0.00019164484071700568,
      "loss": 1.1861,
      "step": 4500
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.3355891704559326,
      "learning_rate": 0.00019071607690164392,
      "loss": 1.1736,
      "step": 5000
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.27807384729385376,
      "learning_rate": 0.00018978917061391289,
      "loss": 1.1666,
      "step": 5500
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.2920401692390442,
      "learning_rate": 0.00018886226432618186,
      "loss": 1.1947,
      "step": 6000
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.30107954144477844,
      "learning_rate": 0.0001879335005108201,
      "loss": 1.1712,
      "step": 6500
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.30822938680648804,
      "learning_rate": 0.00018700473669545835,
      "loss": 1.1725,
      "step": 7000
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.27871984243392944,
      "learning_rate": 0.0001860759728800966,
      "loss": 1.1908,
      "step": 7500
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.31903931498527527,
      "learning_rate": 0.00018514720906473485,
      "loss": 1.1731,
      "step": 8000
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.29311826825141907,
      "learning_rate": 0.0001842184452493731,
      "loss": 1.1735,
      "step": 8500
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.4109500050544739,
      "learning_rate": 0.00018328968143401132,
      "loss": 1.1743,
      "step": 9000
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2619941532611847,
      "learning_rate": 0.00018236091761864959,
      "loss": 1.1777,
      "step": 9500
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.2513294816017151,
      "learning_rate": 0.00018143215380328785,
      "loss": 1.1758,
      "step": 10000
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2908726930618286,
      "learning_rate": 0.00018050338998792608,
      "loss": 1.1836,
      "step": 10500
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3014145493507385,
      "learning_rate": 0.00017957462617256432,
      "loss": 1.1671,
      "step": 11000
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.2681078612804413,
      "learning_rate": 0.0001786477198848333,
      "loss": 1.1746,
      "step": 11500
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3334319591522217,
      "learning_rate": 0.00017771895606947152,
      "loss": 1.1749,
      "step": 12000
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.36518585681915283,
      "learning_rate": 0.0001767901922541098,
      "loss": 1.1727,
      "step": 12500
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.35169506072998047,
      "learning_rate": 0.00017586142843874805,
      "loss": 1.1857,
      "step": 13000
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.2977708876132965,
      "learning_rate": 0.00017493266462338629,
      "loss": 1.1625,
      "step": 13500
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.26458442211151123,
      "learning_rate": 0.00017400390080802452,
      "loss": 1.1903,
      "step": 14000
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.30346596240997314,
      "learning_rate": 0.00017307513699266278,
      "loss": 1.1571,
      "step": 14500
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.28524842858314514,
      "learning_rate": 0.00017214637317730102,
      "loss": 1.1714,
      "step": 15000
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.2825820744037628,
      "learning_rate": 0.00017121946688957,
      "loss": 1.1798,
      "step": 15500
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.2857975661754608,
      "learning_rate": 0.00017029070307420825,
      "loss": 1.1654,
      "step": 16000
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3397250473499298,
      "learning_rate": 0.0001693619392588465,
      "loss": 1.1435,
      "step": 16500
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.316167950630188,
      "learning_rate": 0.00016843317544348472,
      "loss": 1.1733,
      "step": 17000
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.33190304040908813,
      "learning_rate": 0.0001675062691557537,
      "loss": 1.152,
      "step": 17500
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.25945720076560974,
      "learning_rate": 0.00016657750534039193,
      "loss": 1.1581,
      "step": 18000
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3242326080799103,
      "learning_rate": 0.00016565059905266093,
      "loss": 1.1689,
      "step": 18500
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.2978721857070923,
      "learning_rate": 0.00016472183523729916,
      "loss": 1.1488,
      "step": 19000
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3430033326148987,
      "learning_rate": 0.0001637930714219374,
      "loss": 1.1705,
      "step": 19500
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.28607654571533203,
      "learning_rate": 0.00016286430760657566,
      "loss": 1.1562,
      "step": 20000
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.31207534670829773,
      "learning_rate": 0.0001619355437912139,
      "loss": 1.1549,
      "step": 20500
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.3084670305252075,
      "learning_rate": 0.00016100677997585213,
      "loss": 1.1722,
      "step": 21000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.2825249433517456,
      "learning_rate": 0.00016007987368812113,
      "loss": 1.1594,
      "step": 21500
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.28111013770103455,
      "learning_rate": 0.00015915110987275936,
      "loss": 1.16,
      "step": 22000
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.3423774242401123,
      "learning_rate": 0.0001582223460573976,
      "loss": 1.15,
      "step": 22500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2619463801383972,
      "learning_rate": 0.00015729358224203586,
      "loss": 1.152,
      "step": 23000
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.3091576397418976,
      "learning_rate": 0.0001563648184266741,
      "loss": 1.1716,
      "step": 23500
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.28861111402511597,
      "learning_rate": 0.00015543605461131233,
      "loss": 1.1647,
      "step": 24000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.26915061473846436,
      "learning_rate": 0.0001545072907959506,
      "loss": 1.1557,
      "step": 24500
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.3115215003490448,
      "learning_rate": 0.00015358038450821957,
      "loss": 1.1548,
      "step": 25000
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.30721601843833923,
      "learning_rate": 0.0001526516206928578,
      "loss": 1.16,
      "step": 25500
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3231692314147949,
      "learning_rate": 0.00015172285687749606,
      "loss": 1.1469,
      "step": 26000
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.2847815155982971,
      "learning_rate": 0.0001507940930621343,
      "loss": 1.1851,
      "step": 26500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.31246745586395264,
      "learning_rate": 0.00014986532924677253,
      "loss": 1.1514,
      "step": 27000
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.2858879268169403,
      "learning_rate": 0.0001489365654314108,
      "loss": 1.164,
      "step": 27500
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.2564058005809784,
      "learning_rate": 0.00014800780161604903,
      "loss": 1.1571,
      "step": 28000
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.33218711614608765,
      "learning_rate": 0.000147080895328318,
      "loss": 1.167,
      "step": 28500
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.286456435918808,
      "learning_rate": 0.000146153989040587,
      "loss": 1.1563,
      "step": 29000
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.33347150683403015,
      "learning_rate": 0.00014522522522522524,
      "loss": 1.1731,
      "step": 29500
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.273801326751709,
      "learning_rate": 0.00014429646140986347,
      "loss": 1.1652,
      "step": 30000
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.3594479560852051,
      "learning_rate": 0.00014336769759450173,
      "loss": 1.1687,
      "step": 30500
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3516223728656769,
      "learning_rate": 0.00014243893377913997,
      "loss": 1.1713,
      "step": 31000
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2991117537021637,
      "learning_rate": 0.0001415101699637782,
      "loss": 1.1596,
      "step": 31500
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.2956375777721405,
      "learning_rate": 0.00014058140614841647,
      "loss": 1.1623,
      "step": 32000
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.30753782391548157,
      "learning_rate": 0.0001396526423330547,
      "loss": 1.1635,
      "step": 32500
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3137337565422058,
      "learning_rate": 0.00013872387851769294,
      "loss": 1.1698,
      "step": 33000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.3138163387775421,
      "learning_rate": 0.0001377951147023312,
      "loss": 1.1549,
      "step": 33500
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.2975803017616272,
      "learning_rate": 0.00013686820841460017,
      "loss": 1.1648,
      "step": 34000
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.30275940895080566,
      "learning_rate": 0.0001359394445992384,
      "loss": 1.1718,
      "step": 34500
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.2864631712436676,
      "learning_rate": 0.00013501068078387667,
      "loss": 1.1577,
      "step": 35000
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.2997587323188782,
      "learning_rate": 0.0001340819169685149,
      "loss": 1.1646,
      "step": 35500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.154471516609192,
      "eval_runtime": 66.8164,
      "eval_samples_per_second": 200.071,
      "eval_steps_per_second": 25.009,
      "step": 35890
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.27922436594963074,
      "learning_rate": 0.00013315501068078388,
      "loss": 1.16,
      "step": 36000
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.2673499584197998,
      "learning_rate": 0.00013222624686542214,
      "loss": 1.1527,
      "step": 36500
    },
    {
      "epoch": 1.03,
      "grad_norm": 0.31780701875686646,
      "learning_rate": 0.00013129748305006037,
      "loss": 1.165,
      "step": 37000
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.2743293046951294,
      "learning_rate": 0.0001303687192346986,
      "loss": 1.1612,
      "step": 37500
    },
    {
      "epoch": 1.06,
      "grad_norm": 0.3103017807006836,
      "learning_rate": 0.0001294418129469676,
      "loss": 1.1492,
      "step": 38000
    },
    {
      "epoch": 1.07,
      "grad_norm": 0.31575414538383484,
      "learning_rate": 0.00012851304913160584,
      "loss": 1.1596,
      "step": 38500
    },
    {
      "epoch": 1.09,
      "grad_norm": 0.29905617237091064,
      "learning_rate": 0.00012758428531624408,
      "loss": 1.1668,
      "step": 39000
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.31431466341018677,
      "learning_rate": 0.00012665552150088234,
      "loss": 1.1485,
      "step": 39500
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.34300199151039124,
      "learning_rate": 0.00012572675768552058,
      "loss": 1.1681,
      "step": 40000
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.3621000647544861,
      "learning_rate": 0.0001247979938701588,
      "loss": 1.1511,
      "step": 40500
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.27860385179519653,
      "learning_rate": 0.00012386923005479707,
      "loss": 1.1643,
      "step": 41000
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.256878525018692,
      "learning_rate": 0.0001229404662394353,
      "loss": 1.1538,
      "step": 41500
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.2733500897884369,
      "learning_rate": 0.00012201355995170429,
      "loss": 1.1601,
      "step": 42000
    },
    {
      "epoch": 1.18,
      "grad_norm": 0.3330339789390564,
      "learning_rate": 0.00012108479613634254,
      "loss": 1.154,
      "step": 42500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.33120524883270264,
      "learning_rate": 0.00012015603232098078,
      "loss": 1.1739,
      "step": 43000
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.33479630947113037,
      "learning_rate": 0.00011922726850561903,
      "loss": 1.1596,
      "step": 43500
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.2980976104736328,
      "learning_rate": 0.00011829850469025728,
      "loss": 1.1793,
      "step": 44000
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.2867085635662079,
      "learning_rate": 0.00011736974087489551,
      "loss": 1.1669,
      "step": 44500
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.30577653646469116,
      "learning_rate": 0.00011644097705953376,
      "loss": 1.1664,
      "step": 45000
    },
    {
      "epoch": 1.27,
      "grad_norm": 0.3085036873817444,
      "learning_rate": 0.00011551221324417201,
      "loss": 1.1629,
      "step": 45500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.29713186621665955,
      "learning_rate": 0.00011458530695644098,
      "loss": 1.1447,
      "step": 46000
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.32120010256767273,
      "learning_rate": 0.00011365654314107923,
      "loss": 1.1516,
      "step": 46500
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.28039196133613586,
      "learning_rate": 0.00011272777932571748,
      "loss": 1.1658,
      "step": 47000
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.2849559783935547,
      "learning_rate": 0.00011179901551035571,
      "loss": 1.1411,
      "step": 47500
    },
    {
      "epoch": 1.34,
      "grad_norm": 0.37301352620124817,
      "learning_rate": 0.0001108721092226247,
      "loss": 1.1663,
      "step": 48000
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.3063981235027313,
      "learning_rate": 0.00010994334540726295,
      "loss": 1.147,
      "step": 48500
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.30691176652908325,
      "learning_rate": 0.00010901458159190118,
      "loss": 1.1661,
      "step": 49000
    },
    {
      "epoch": 1.38,
      "grad_norm": 0.2649722397327423,
      "learning_rate": 0.00010808581777653943,
      "loss": 1.1432,
      "step": 49500
    },
    {
      "epoch": 1.39,
      "grad_norm": 0.31021204590797424,
      "learning_rate": 0.00010715705396117768,
      "loss": 1.1652,
      "step": 50000
    },
    {
      "epoch": 1.41,
      "grad_norm": 0.34651508927345276,
      "learning_rate": 0.00010622829014581593,
      "loss": 1.1666,
      "step": 50500
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.29828688502311707,
      "learning_rate": 0.00010529952633045416,
      "loss": 1.1637,
      "step": 51000
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.3078192174434662,
      "learning_rate": 0.00010437076251509241,
      "loss": 1.1855,
      "step": 51500
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.3145574927330017,
      "learning_rate": 0.00010344199869973066,
      "loss": 1.1662,
      "step": 52000
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.27572983503341675,
      "learning_rate": 0.00010251509241199963,
      "loss": 1.1605,
      "step": 52500
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.2902051508426666,
      "learning_rate": 0.00010158632859663788,
      "loss": 1.1544,
      "step": 53000
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.2656576335430145,
      "learning_rate": 0.00010065756478127613,
      "loss": 1.1548,
      "step": 53500
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.34100478887557983,
      "learning_rate": 9.972880096591437e-05,
      "loss": 1.1587,
      "step": 54000
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.30414387583732605,
      "learning_rate": 9.880003715055262e-05,
      "loss": 1.1599,
      "step": 54500
    },
    {
      "epoch": 1.53,
      "grad_norm": 0.32570070028305054,
      "learning_rate": 9.787127333519086e-05,
      "loss": 1.1658,
      "step": 55000
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.3142200708389282,
      "learning_rate": 9.694250951982911e-05,
      "loss": 1.1414,
      "step": 55500
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.30952581763267517,
      "learning_rate": 9.601374570446736e-05,
      "loss": 1.1528,
      "step": 56000
    },
    {
      "epoch": 1.57,
      "grad_norm": 0.3323597311973572,
      "learning_rate": 9.508683941673633e-05,
      "loss": 1.1708,
      "step": 56500
    },
    {
      "epoch": 1.59,
      "grad_norm": 0.3156532347202301,
      "learning_rate": 9.415807560137457e-05,
      "loss": 1.1472,
      "step": 57000
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.329536497592926,
      "learning_rate": 9.322931178601282e-05,
      "loss": 1.1645,
      "step": 57500
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.3492265045642853,
      "learning_rate": 9.230054797065107e-05,
      "loss": 1.16,
      "step": 58000
    },
    {
      "epoch": 1.63,
      "grad_norm": 0.28792425990104675,
      "learning_rate": 9.137549921055076e-05,
      "loss": 1.1518,
      "step": 58500
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.31680813431739807,
      "learning_rate": 9.0446735395189e-05,
      "loss": 1.1605,
      "step": 59000
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.2534569203853607,
      "learning_rate": 8.951797157982726e-05,
      "loss": 1.1542,
      "step": 59500
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.341339647769928,
      "learning_rate": 8.85892077644655e-05,
      "loss": 1.1688,
      "step": 60000
    },
    {
      "epoch": 1.69,
      "grad_norm": 0.2409754991531372,
      "learning_rate": 8.766044394910374e-05,
      "loss": 1.1678,
      "step": 60500
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.3033386468887329,
      "learning_rate": 8.673168013374199e-05,
      "loss": 1.1542,
      "step": 61000
    },
    {
      "epoch": 1.71,
      "grad_norm": 0.29392698407173157,
      "learning_rate": 8.580291631838024e-05,
      "loss": 1.15,
      "step": 61500
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.28256407380104065,
      "learning_rate": 8.487415250301849e-05,
      "loss": 1.1573,
      "step": 62000
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.2754587233066559,
      "learning_rate": 8.394724621528746e-05,
      "loss": 1.1732,
      "step": 62500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.28353381156921387,
      "learning_rate": 8.302033992755643e-05,
      "loss": 1.1633,
      "step": 63000
    },
    {
      "epoch": 1.77,
      "grad_norm": 0.30000683665275574,
      "learning_rate": 8.209157611219466e-05,
      "loss": 1.1622,
      "step": 63500
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.31057626008987427,
      "learning_rate": 8.116281229683293e-05,
      "loss": 1.1689,
      "step": 64000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.30336257815361023,
      "learning_rate": 8.02359060091019e-05,
      "loss": 1.1699,
      "step": 64500
    },
    {
      "epoch": 1.81,
      "grad_norm": 0.2914707362651825,
      "learning_rate": 7.930714219374013e-05,
      "loss": 1.1424,
      "step": 65000
    },
    {
      "epoch": 1.83,
      "grad_norm": 0.25281965732574463,
      "learning_rate": 7.837837837837838e-05,
      "loss": 1.1726,
      "step": 65500
    },
    {
      "epoch": 1.84,
      "grad_norm": 0.27423256635665894,
      "learning_rate": 7.744961456301663e-05,
      "loss": 1.1685,
      "step": 66000
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.31427210569381714,
      "learning_rate": 7.652085074765487e-05,
      "loss": 1.1582,
      "step": 66500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.3473736047744751,
      "learning_rate": 7.559208693229313e-05,
      "loss": 1.1616,
      "step": 67000
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.3089316785335541,
      "learning_rate": 7.466332311693138e-05,
      "loss": 1.1486,
      "step": 67500
    },
    {
      "epoch": 1.89,
      "grad_norm": 0.37206095457077026,
      "learning_rate": 7.373455930156961e-05,
      "loss": 1.1469,
      "step": 68000
    },
    {
      "epoch": 1.91,
      "grad_norm": 0.31066790223121643,
      "learning_rate": 7.280579548620786e-05,
      "loss": 1.1596,
      "step": 68500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.3369779586791992,
      "learning_rate": 7.187703167084611e-05,
      "loss": 1.1479,
      "step": 69000
    },
    {
      "epoch": 1.94,
      "grad_norm": 0.35136187076568604,
      "learning_rate": 7.094826785548435e-05,
      "loss": 1.1476,
      "step": 69500
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.3086129426956177,
      "learning_rate": 7.00195040401226e-05,
      "loss": 1.1715,
      "step": 70000
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.324016809463501,
      "learning_rate": 6.909259775239158e-05,
      "loss": 1.145,
      "step": 70500
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.3090330958366394,
      "learning_rate": 6.816383393702981e-05,
      "loss": 1.1582,
      "step": 71000
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.28177815675735474,
      "learning_rate": 6.723692764929878e-05,
      "loss": 1.167,
      "step": 71500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.1495018005371094,
      "eval_runtime": 66.8193,
      "eval_samples_per_second": 200.062,
      "eval_steps_per_second": 25.008,
      "step": 71780
    },
    {
      "epoch": 2.01,
      "grad_norm": 0.2587859332561493,
      "learning_rate": 6.630816383393703e-05,
      "loss": 1.1706,
      "step": 72000
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.3119889497756958,
      "learning_rate": 6.537940001857528e-05,
      "loss": 1.1386,
      "step": 72500
    },
    {
      "epoch": 2.03,
      "grad_norm": 0.35506290197372437,
      "learning_rate": 6.445063620321352e-05,
      "loss": 1.1555,
      "step": 73000
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.2844965159893036,
      "learning_rate": 6.352187238785178e-05,
      "loss": 1.1627,
      "step": 73500
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.32015368342399597,
      "learning_rate": 6.259496610012074e-05,
      "loss": 1.1588,
      "step": 74000
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.28982627391815186,
      "learning_rate": 6.166620228475899e-05,
      "loss": 1.1504,
      "step": 74500
    },
    {
      "epoch": 2.09,
      "grad_norm": 0.3147021532058716,
      "learning_rate": 6.073929599702796e-05,
      "loss": 1.1486,
      "step": 75000
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.3228665888309479,
      "learning_rate": 5.98105321816662e-05,
      "loss": 1.1586,
      "step": 75500
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.40550389885902405,
      "learning_rate": 5.888176836630445e-05,
      "loss": 1.1425,
      "step": 76000
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.3084259033203125,
      "learning_rate": 5.7953004550942704e-05,
      "loss": 1.1744,
      "step": 76500
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.3055843710899353,
      "learning_rate": 5.7024240735580946e-05,
      "loss": 1.1636,
      "step": 77000
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.2928888201713562,
      "learning_rate": 5.6097334447849916e-05,
      "loss": 1.1624,
      "step": 77500
    },
    {
      "epoch": 2.17,
      "grad_norm": 0.30190759897232056,
      "learning_rate": 5.516857063248816e-05,
      "loss": 1.1666,
      "step": 78000
    },
    {
      "epoch": 2.19,
      "grad_norm": 0.3373946249485016,
      "learning_rate": 5.42398068171264e-05,
      "loss": 1.1454,
      "step": 78500
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.29586365818977356,
      "learning_rate": 5.331104300176465e-05,
      "loss": 1.1668,
      "step": 79000
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.3393253684043884,
      "learning_rate": 5.2382279186402906e-05,
      "loss": 1.1661,
      "step": 79500
    },
    {
      "epoch": 2.23,
      "grad_norm": 0.30446040630340576,
      "learning_rate": 5.145351537104115e-05,
      "loss": 1.1698,
      "step": 80000
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3316879868507385,
      "learning_rate": 5.05247515556794e-05,
      "loss": 1.1502,
      "step": 80500
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.3699677288532257,
      "learning_rate": 4.959598774031764e-05,
      "loss": 1.1582,
      "step": 81000
    },
    {
      "epoch": 2.27,
      "grad_norm": 0.3258490562438965,
      "learning_rate": 4.866722392495588e-05,
      "loss": 1.1639,
      "step": 81500
    },
    {
      "epoch": 2.28,
      "grad_norm": 0.30180060863494873,
      "learning_rate": 4.773846010959413e-05,
      "loss": 1.1521,
      "step": 82000
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.31700631976127625,
      "learning_rate": 4.680969629423238e-05,
      "loss": 1.171,
      "step": 82500
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.2983833849430084,
      "learning_rate": 4.588279000650135e-05,
      "loss": 1.1781,
      "step": 83000
    },
    {
      "epoch": 2.33,
      "grad_norm": 0.27958205342292786,
      "learning_rate": 4.49540261911396e-05,
      "loss": 1.1595,
      "step": 83500
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.2719099819660187,
      "learning_rate": 4.402711990340856e-05,
      "loss": 1.1484,
      "step": 84000
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.267642080783844,
      "learning_rate": 4.309835608804681e-05,
      "loss": 1.1515,
      "step": 84500
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.3342951834201813,
      "learning_rate": 4.216959227268506e-05,
      "loss": 1.1477,
      "step": 85000
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.30088117718696594,
      "learning_rate": 4.12408284573233e-05,
      "loss": 1.149,
      "step": 85500
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.3218640387058258,
      "learning_rate": 4.031206464196155e-05,
      "loss": 1.1547,
      "step": 86000
    },
    {
      "epoch": 2.41,
      "grad_norm": 0.3240850269794464,
      "learning_rate": 3.9383300826599795e-05,
      "loss": 1.1587,
      "step": 86500
    },
    {
      "epoch": 2.42,
      "grad_norm": 0.36872005462646484,
      "learning_rate": 3.8456394538868765e-05,
      "loss": 1.1459,
      "step": 87000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.32296353578567505,
      "learning_rate": 3.7527630723507014e-05,
      "loss": 1.159,
      "step": 87500
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.2884490191936493,
      "learning_rate": 3.659886690814526e-05,
      "loss": 1.1576,
      "step": 88000
    },
    {
      "epoch": 2.47,
      "grad_norm": 0.2808411717414856,
      "learning_rate": 3.5670103092783505e-05,
      "loss": 1.1552,
      "step": 88500
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.30229875445365906,
      "learning_rate": 3.4741339277421754e-05,
      "loss": 1.1453,
      "step": 89000
    },
    {
      "epoch": 2.49,
      "grad_norm": 0.24707356095314026,
      "learning_rate": 3.381257546206e-05,
      "loss": 1.1528,
      "step": 89500
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.3849768340587616,
      "learning_rate": 3.2883811646698246e-05,
      "loss": 1.1597,
      "step": 90000
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.3269411623477936,
      "learning_rate": 3.1955047831336495e-05,
      "loss": 1.1398,
      "step": 90500
    },
    {
      "epoch": 2.54,
      "grad_norm": 0.32099437713623047,
      "learning_rate": 3.102628401597474e-05,
      "loss": 1.1594,
      "step": 91000
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.3250938653945923,
      "learning_rate": 3.009937772824371e-05,
      "loss": 1.1356,
      "step": 91500
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.32461029291152954,
      "learning_rate": 2.9170613912881956e-05,
      "loss": 1.1648,
      "step": 92000
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.284841924905777,
      "learning_rate": 2.82418500975202e-05,
      "loss": 1.165,
      "step": 92500
    },
    {
      "epoch": 2.59,
      "grad_norm": 0.3195631802082062,
      "learning_rate": 2.731308628215845e-05,
      "loss": 1.1582,
      "step": 93000
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.3481299579143524,
      "learning_rate": 2.6384322466796697e-05,
      "loss": 1.1633,
      "step": 93500
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.2940222918987274,
      "learning_rate": 2.545555865143494e-05,
      "loss": 1.1477,
      "step": 94000
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.2947961688041687,
      "learning_rate": 2.452865236370391e-05,
      "loss": 1.1405,
      "step": 94500
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.32308852672576904,
      "learning_rate": 2.359988854834216e-05,
      "loss": 1.1605,
      "step": 95000
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.27816009521484375,
      "learning_rate": 2.2671124732980404e-05,
      "loss": 1.1483,
      "step": 95500
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.35921505093574524,
      "learning_rate": 2.174236091761865e-05,
      "loss": 1.156,
      "step": 96000
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.27847757935523987,
      "learning_rate": 2.0813597102256896e-05,
      "loss": 1.1492,
      "step": 96500
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.3856862783432007,
      "learning_rate": 1.9886690814525866e-05,
      "loss": 1.1519,
      "step": 97000
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.3057786524295807,
      "learning_rate": 1.8957926999164115e-05,
      "loss": 1.1613,
      "step": 97500
    },
    {
      "epoch": 2.73,
      "grad_norm": 0.3231293857097626,
      "learning_rate": 1.802916318380236e-05,
      "loss": 1.1727,
      "step": 98000
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.3002363443374634,
      "learning_rate": 1.7100399368440606e-05,
      "loss": 1.1599,
      "step": 98500
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.31947919726371765,
      "learning_rate": 1.6171635553078855e-05,
      "loss": 1.1547,
      "step": 99000
    },
    {
      "epoch": 2.77,
      "grad_norm": 0.3040955364704132,
      "learning_rate": 1.52428717377171e-05,
      "loss": 1.1585,
      "step": 99500
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.30903637409210205,
      "learning_rate": 1.4314107922355347e-05,
      "loss": 1.1565,
      "step": 100000
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.3234305679798126,
      "learning_rate": 1.3385344106993591e-05,
      "loss": 1.1508,
      "step": 100500
    },
    {
      "epoch": 2.81,
      "grad_norm": 0.3104691803455353,
      "learning_rate": 1.2456580291631838e-05,
      "loss": 1.1426,
      "step": 101000
    },
    {
      "epoch": 2.83,
      "grad_norm": 0.3333328366279602,
      "learning_rate": 1.1531531531531532e-05,
      "loss": 1.1491,
      "step": 101500
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.29323023557662964,
      "learning_rate": 1.0602767716169778e-05,
      "loss": 1.1629,
      "step": 102000
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.2893976867198944,
      "learning_rate": 9.675861428438748e-06,
      "loss": 1.1654,
      "step": 102500
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.3079429864883423,
      "learning_rate": 8.747097613076995e-06,
      "loss": 1.1515,
      "step": 103000
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.3514176905155182,
      "learning_rate": 7.818333797715241e-06,
      "loss": 1.1559,
      "step": 103500
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.3474714457988739,
      "learning_rate": 6.889569982353487e-06,
      "loss": 1.1599,
      "step": 104000
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.30364468693733215,
      "learning_rate": 5.962663694622458e-06,
      "loss": 1.1451,
      "step": 104500
    },
    {
      "epoch": 2.93,
      "grad_norm": 0.3344711661338806,
      "learning_rate": 5.033899879260704e-06,
      "loss": 1.1554,
      "step": 105000
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.29949769377708435,
      "learning_rate": 4.10513606389895e-06,
      "loss": 1.1705,
      "step": 105500
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.298883855342865,
      "learning_rate": 3.1763722485371975e-06,
      "loss": 1.1511,
      "step": 106000
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.33835530281066895,
      "learning_rate": 2.2476084331754433e-06,
      "loss": 1.1427,
      "step": 106500
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.2648980915546417,
      "learning_rate": 1.31884461781369e-06,
      "loss": 1.1502,
      "step": 107000
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.30639562010765076,
      "learning_rate": 3.900808024519365e-07,
      "loss": 1.1474,
      "step": 107500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.1476236581802368,
      "eval_runtime": 66.8233,
      "eval_samples_per_second": 200.05,
      "eval_steps_per_second": 25.006,
      "step": 107670
    }
  ],
  "logging_steps": 500,
  "max_steps": 107670,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 1.173555189425111e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
